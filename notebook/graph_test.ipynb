{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "     print(\"CUDA is available.\")\n",
    "else:\n",
    "     print(\"CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\coreferee_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.graph_utils import create_graph, embed_nodes, convert_graph_from_nx_to_pyg, get_node_sent_map,get_embed_graph_node_map\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_preprocess_utils import load_jsonl, define_node_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(\"..\",\"data\", \"multinews\", \"test.jsonl\")\n",
    "docs_list, summary_list = load_jsonl(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n",
      "padding sent_emb size:  torch.Size([768])\n",
      "positon_embeddings size:  torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "word_nodeId_list, sent_nodeId_list, edge_data_list,sentid_node_map_list = define_node_edge(docs_list, 0.5)\n",
    "graph_list = create_graph(word_nodeId_list, sent_nodeId_list, edge_data_list)\n",
    "embedded_graph_list = embed_nodes(graph_list, sentid_node_map_list)\n",
    "pyg_graph_list, nodeid_to_sent_map_list = convert_graph_from_nx_to_pyg(embedded_graph_list)\n",
    "node_sent_map_list = get_node_sent_map(embedded_graph_list, nodeid_to_sent_map_list) ## (type, id) -> sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grapg in graph_list:\n",
    "     for node in grapg.nodes():\n",
    "          attributes = grapg.nodes[node]\n",
    "          if not attributes['type'] == 'word': continue\n",
    "          print(f\"Node {node} has attributes: {attributes['type']}, {attributes['text']}\")\n",
    "          print(f\"Node {node} has embedding: {attributes['embedding'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge: (20, 6), Attributes: {'edge_type': 'word_sent', 'weight': 0.4743}\n",
      "Edge: (20, 12), Attributes: {'edge_type': 'word_sent', 'weight': 0.5112}\n",
      "Edge: (20, 14), Attributes: {'edge_type': 'word_sent', 'weight': 0.5112}\n",
      "Edge: (20, 16), Attributes: {'edge_type': 'word_sent', 'weight': 0.5112}\n",
      "Edge: (21, 5), Attributes: {'edge_type': 'word_sent', 'weight': 0.2088}\n",
      "Edge: (22, 12), Attributes: {'edge_type': 'word_sent', 'weight': 0.1893}\n",
      "Edge: (22, 14), Attributes: {'edge_type': 'word_sent', 'weight': 0.1893}\n",
      "Edge: (22, 15), Attributes: {'edge_type': 'word_sent', 'weight': 0.1893}\n",
      "Edge: (5, 21), Attributes: {'edge_type': 'word_sent', 'weight': 0.2088}\n",
      "Edge: (6, 20), Attributes: {'edge_type': 'word_sent', 'weight': 0.4743}\n",
      "Edge: (12, 20), Attributes: {'edge_type': 'word_sent', 'weight': 0.5112}\n",
      "Edge: (12, 22), Attributes: {'edge_type': 'word_sent', 'weight': 0.1893}\n",
      "Edge: (14, 20), Attributes: {'edge_type': 'word_sent', 'weight': 0.5112}\n",
      "Edge: (14, 22), Attributes: {'edge_type': 'word_sent', 'weight': 0.1893}\n",
      "Edge: (15, 22), Attributes: {'edge_type': 'word_sent', 'weight': 0.1893}\n",
      "Edge: (16, 20), Attributes: {'edge_type': 'word_sent', 'weight': 0.5112}\n",
      "Edge: (46, 1), Attributes: {'edge_type': 'word_sent', 'weight': 0.4617}\n",
      "Edge: (46, 4), Attributes: {'edge_type': 'word_sent', 'weight': 0.4617}\n",
      "Edge: (46, 10), Attributes: {'edge_type': 'word_sent', 'weight': 0.3867}\n",
      "Edge: (46, 14), Attributes: {'edge_type': 'word_sent', 'weight': 0.3867}\n",
      "Edge: (46, 30), Attributes: {'edge_type': 'word_sent', 'weight': 0.3867}\n",
      "Edge: (47, 6), Attributes: {'edge_type': 'word_sent', 'weight': 0.2214}\n",
      "Edge: (47, 16), Attributes: {'edge_type': 'word_sent', 'weight': 0.2684}\n",
      "Edge: (1, 46), Attributes: {'edge_type': 'word_sent', 'weight': 0.4617}\n",
      "Edge: (4, 46), Attributes: {'edge_type': 'word_sent', 'weight': 0.4617}\n",
      "Edge: (6, 47), Attributes: {'edge_type': 'word_sent', 'weight': 0.2214}\n",
      "Edge: (10, 46), Attributes: {'edge_type': 'word_sent', 'weight': 0.3867}\n",
      "Edge: (14, 46), Attributes: {'edge_type': 'word_sent', 'weight': 0.3867}\n",
      "Edge: (16, 47), Attributes: {'edge_type': 'word_sent', 'weight': 0.2684}\n",
      "Edge: (30, 46), Attributes: {'edge_type': 'word_sent', 'weight': 0.3867}\n"
     ]
    }
   ],
   "source": [
    "for grapg in graph_list:\n",
    "     for u, v, data in grapg.edges(data=True):\n",
    "          if not data['edge_type'] == 'word_sent': continue\n",
    "          print(f\"Edge: ({u}, {v}), Attributes: {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph construct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs_list = [[\n",
    "     [\"Although he was very busy with his work, Peter had had enough of it. He and his wife decided they needed a holiday. They travelled to Spain because they loved the country very much.\"],\n",
    "     [\"A stray cat appeared in the garden one rainy day. Sarah offered milk and a blanket. It stayed, becoming part of her family.\"],\n",
    "     [\"The bakery’s croissants were legendary. Every morning, the scent of butter drew a crowd. Mrs. Laurent, the baker, perfected each one. Customers claimed they were the best they’d ever tasted.\"]\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\coreferee_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.data_preprocess_utils import define_node_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_map, sent_map, edges, sentid_map = define_node_edge(test_docs_list, edge_similarity_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.graph_utils import create_graph, embed_nodes, convert_graph_from_nx_to_pyg, get_node_sent_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list = create_graph(word_map, sent_map, edges)\n",
    "graph_emb_list = embed_nodes(graph_list, sentid_map)\n",
    "pyg_graph_list, nodeid_to_sent_map_list = convert_graph_from_nx_to_pyg(graph_emb_list)\n",
    "node_sent_map_list = get_node_sent_map(graph_emb_list, nodeid_to_sent_map_list) ## (type, id) -> sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 has attributes: sentence, Although he was very busy with his work, Peter had had enough of it.\n",
      "Node 0 has embedding: tensor([-0.0208, -0.0202,  0.0457,  0.0079,  0.0253])\n",
      "Node 1 has attributes: sentence, He and his wife decided they needed a holiday.\n",
      "Node 1 has embedding: tensor([ 0.0025,  0.0112,  0.0190, -0.0044, -0.0230])\n",
      "Node 2 has attributes: sentence, They travelled to Spain because they loved the country very much.\n",
      "Node 2 has embedding: tensor([-0.0134,  0.0093,  0.0060, -0.0256, -0.0333])\n",
      "Node 3 has attributes: sentence, A stray cat appeared in the garden one rainy day.\n",
      "Node 3 has embedding: tensor([ 0.0477, -0.0383,  0.0004, -0.0512, -0.0355])\n",
      "Node 4 has attributes: sentence, Sarah offered milk and a blanket.\n",
      "Node 4 has embedding: tensor([ 0.0697,  0.0130, -0.0009, -0.0090, -0.0110])\n",
      "Node 5 has attributes: sentence, It stayed, becoming part of her family.\n",
      "Node 5 has embedding: tensor([ 0.0488, -0.0220,  0.0437,  0.0205, -0.0013])\n",
      "Node 6 has attributes: sentence, The bakery’s croissants were legendary.\n",
      "Node 6 has embedding: tensor([-0.0320,  0.0073, -0.0158, -0.0072, -0.0262])\n",
      "Node 7 has attributes: sentence, Every morning, the scent of butter drew a crowd.\n",
      "Node 7 has embedding: tensor([-0.0266,  0.0184,  0.0222, -0.0175,  0.0422])\n",
      "Node 8 has attributes: sentence, Mrs. Laurent, the baker, perfected each one.\n",
      "Node 8 has embedding: tensor([-0.0251, -0.0229, -0.0099, -0.0350, -0.0390])\n",
      "Node 9 has attributes: sentence, Customers claimed they were the best they’d ever tasted.\n",
      "Node 9 has embedding: tensor([-0.0116, -0.0288,  0.0224, -0.0070,  0.0148])\n"
     ]
    }
   ],
   "source": [
    "for node in graph_list[0].nodes():\n",
    "     attributes = graph_list[0].nodes[node]\n",
    "     if not attributes['type']== 'sentence': continue\n",
    "     print(f\"Node {node} has attributes: {attributes['type']}, {attributes['text'][2]}\")\n",
    "     print(f\"Node {node} has embedding: {attributes['embedding'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent 0, tensor([-0.0208, -0.0202,  0.0457,  0.0079,  0.0253])\n",
      "sent 1, tensor([ 0.0025,  0.0112,  0.0190, -0.0044, -0.0230])\n",
      "sent 2, tensor([-0.0134,  0.0093,  0.0060, -0.0256, -0.0333])\n",
      "sent 3, tensor([ 0.0477, -0.0383,  0.0004, -0.0512, -0.0355])\n",
      "sent 4, tensor([ 0.0697,  0.0130, -0.0009, -0.0090, -0.0110])\n",
      "sent 5, tensor([ 0.0488, -0.0220,  0.0437,  0.0205, -0.0013])\n",
      "sent 6, tensor([-0.0320,  0.0073, -0.0158, -0.0072, -0.0262])\n",
      "sent 7, tensor([-0.0266,  0.0184,  0.0222, -0.0175,  0.0422])\n",
      "sent 8, tensor([-0.0251, -0.0229, -0.0099, -0.0350, -0.0390])\n",
      "sent 9, tensor([-0.0116, -0.0288,  0.0224, -0.0070,  0.0148])\n"
     ]
    }
   ],
   "source": [
    "for pyg_graph in pyg_graph_list:\n",
    "     id = 0\n",
    "     for set in pyg_graph['sentence'].x:\n",
    "          print(f\"sent {id}, {set[:5]}\")\n",
    "          id = id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: ('sentence', 0), Value: Although he was very busy with his work, Peter had had enough of it.\n",
      "Key: ('sentence', 1), Value: He and his wife decided they needed a holiday.\n",
      "Key: ('sentence', 2), Value: They travelled to Spain because they loved the country very much.\n",
      "Key: ('sentence', 3), Value: A stray cat appeared in the garden one rainy day.\n",
      "Key: ('sentence', 4), Value: Sarah offered milk and a blanket.\n",
      "Key: ('sentence', 5), Value: It stayed, becoming part of her family.\n",
      "Key: ('sentence', 6), Value: The bakery’s croissants were legendary.\n",
      "Key: ('sentence', 7), Value: Every morning, the scent of butter drew a crowd.\n",
      "Key: ('sentence', 8), Value: Mrs. Laurent, the baker, perfected each one.\n",
      "Key: ('sentence', 9), Value: Customers claimed they were the best they’d ever tasted.\n"
     ]
    }
   ],
   "source": [
    "for map in node_sent_map_list:\n",
    "     for key, value in map.items():\n",
    "          print(f\"Key: {key}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.graph_utils import create_embed_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: ('sentence', 0), Value: Although he was very busy with his work, Peter had had enough of it.\n",
      "Key: ('sentence', 1), Value: He and his wife decided they needed a holiday.\n",
      "Key: ('sentence', 2), Value: They travelled to Spain because they loved the country very much.\n",
      "Key: ('sentence', 3), Value: A stray cat appeared in the garden one rainy day.\n",
      "Key: ('sentence', 4), Value: Sarah offered milk and a blanket.\n",
      "Key: ('sentence', 5), Value: It stayed, becoming part of her family.\n",
      "Key: ('sentence', 6), Value: The bakery’s croissants were legendary.\n",
      "Key: ('sentence', 7), Value: Every morning, the scent of butter drew a crowd.\n",
      "Key: ('sentence', 8), Value: Mrs. Laurent, the baker, perfected each one.\n",
      "Key: ('sentence', 9), Value: Customers claimed they were the best they’d ever tasted.\n"
     ]
    }
   ],
   "source": [
    "sample_graphs, node_maps = create_embed_graphs(test_docs_list)\n",
    "for a in node_maps:\n",
    "     for key, value in a.items():\n",
    "          print(f\"Key: {key}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge: (10, 0), Attributes: {'edge_type': 'word_sent', 'weight': 0.4611}\n",
      "Edge: (11, 2), Attributes: {'edge_type': 'word_sent', 'weight': 0.2796}\n",
      "Edge: (12, 3), Attributes: {'edge_type': 'word_sent', 'weight': 0.4608}\n",
      "Edge: (13, 4), Attributes: {'edge_type': 'word_sent', 'weight': 0.1903}\n",
      "Edge: (14, 6), Attributes: {'edge_type': 'word_sent', 'weight': 0.6856}\n",
      "Edge: (15, 8), Attributes: {'edge_type': 'word_sent', 'weight': 0.284}\n",
      "Edge: (0, 10), Attributes: {'edge_type': 'word_sent', 'weight': 0.4611}\n",
      "Edge: (0, 1), Attributes: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "Edge: (0, 1), Attributes: {'edge_type': 'similarity', 'weight': tensor(0.3666)}\n",
      "Edge: (1, 0), Attributes: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "Edge: (1, 0), Attributes: {'edge_type': 'similarity', 'weight': tensor(0.3666)}\n",
      "Edge: (1, 2), Attributes: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "Edge: (1, 2), Attributes: {'edge_type': 'similarity', 'weight': tensor(0.3891)}\n",
      "Edge: (2, 11), Attributes: {'edge_type': 'word_sent', 'weight': 0.2796}\n",
      "Edge: (2, 1), Attributes: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "Edge: (2, 1), Attributes: {'edge_type': 'similarity', 'weight': tensor(0.3891)}\n",
      "Edge: (3, 12), Attributes: {'edge_type': 'word_sent', 'weight': 0.4608}\n",
      "Edge: (3, 5), Attributes: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "Edge: (4, 13), Attributes: {'edge_type': 'word_sent', 'weight': 0.1903}\n",
      "Edge: (4, 5), Attributes: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "Edge: (5, 3), Attributes: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "Edge: (5, 4), Attributes: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "Edge: (6, 14), Attributes: {'edge_type': 'word_sent', 'weight': 0.6856}\n",
      "Edge: (6, 8), Attributes: {'edge_type': 'similarity', 'weight': tensor(0.4890)}\n",
      "Edge: (6, 9), Attributes: {'edge_type': 'similarity', 'weight': tensor(0.3625)}\n",
      "Edge: (8, 15), Attributes: {'edge_type': 'word_sent', 'weight': 0.284}\n",
      "Edge: (8, 6), Attributes: {'edge_type': 'similarity', 'weight': tensor(0.4890)}\n",
      "Edge: (9, 6), Attributes: {'edge_type': 'similarity', 'weight': tensor(0.3625)}\n"
     ]
    }
   ],
   "source": [
    "for u, v, data in graph_list[0].edges(data=True):\n",
    "     print(f\"Edge: ({u}, {v}), Attributes: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.19it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_graph_li = create_embed_graphs(test_docs_list, sent_similarity = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点: 10, 属性: tensor([-0.0323, -0.0288, -0.0082, -0.0329,  0.0092])\n",
      "节点: 11, 属性: tensor([-0.0242, -0.0111, -0.0089,  0.0018,  0.0010])\n",
      "节点: 12, 属性: tensor([-0.0027, -0.0073,  0.0136, -0.0221, -0.0268])\n",
      "节点: 13, 属性: tensor([-0.0121, -0.0111, -0.0278, -0.0111,  0.0074])\n",
      "节点: 14, 属性: tensor([-0.0481, -0.0267, -0.0167, -0.0252, -0.0145])\n",
      "节点: 15, 属性: tensor([-0.0086, -0.0254, -0.0143, -0.0023, -0.0113])\n",
      "节点: 0, 属性: tensor([ 0.0095,  0.0421, -0.0144, -0.0568, -0.0043])\n",
      "节点: 1, 属性: tensor([ 0.0188,  0.0256,  0.0216, -0.0421, -0.0053])\n",
      "节点: 2, 属性: tensor([ 0.0126,  0.0107,  0.0048, -0.0699, -0.0131])\n",
      "节点: 3, 属性: tensor([ 0.0101,  0.0030,  0.0125, -0.0075, -0.0299])\n",
      "节点: 4, 属性: tensor([ 0.0122,  0.0110, -0.0345, -0.0405,  0.0142])\n",
      "节点: 5, 属性: tensor([ 0.0059,  0.0013, -0.0363, -0.0292, -0.0292])\n",
      "节点: 6, 属性: tensor([-0.0001,  0.0206,  0.0010,  0.0508, -0.0447])\n",
      "节点: 7, 属性: tensor([ 0.0244, -0.0280,  0.0067,  0.0413, -0.0166])\n",
      "节点: 8, 属性: tensor([-0.0136,  0.0101,  0.0215,  0.0626, -0.0461])\n",
      "节点: 9, 属性: tensor([ 0.0321, -0.0042, -0.0341,  0.0908, -0.0357])\n"
     ]
    }
   ],
   "source": [
    "for node in graph_emb_list[0].nodes():\n",
    "     print(f\"节点: {node}, 属性: {graph_emb_list[0].nodes[node]['embedding'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "边: 10 -> 0, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.4611}\n",
      "边: 11 -> 2, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.2796}\n",
      "边: 12 -> 3, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.4608}\n",
      "边: 13 -> 4, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.1903}\n",
      "边: 14 -> 6, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.6856}\n",
      "边: 15 -> 8, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.284}\n",
      "边: 0 -> 10, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.4611}\n",
      "边: 0 -> 1, 键: 0, 属性: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "边: 0 -> 1, 键: 1, 属性: {'edge_type': 'similarity', 'weight': 0.36655884981155396}\n",
      "边: 1 -> 0, 键: 0, 属性: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "边: 1 -> 0, 键: 1, 属性: {'edge_type': 'similarity', 'weight': 0.36655884981155396}\n",
      "边: 1 -> 2, 键: 0, 属性: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "边: 1 -> 2, 键: 1, 属性: {'edge_type': 'similarity', 'weight': 0.3890610337257385}\n",
      "边: 2 -> 11, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.2796}\n",
      "边: 2 -> 1, 键: 0, 属性: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "边: 2 -> 1, 键: 1, 属性: {'edge_type': 'similarity', 'weight': 0.3890610337257385}\n",
      "边: 3 -> 12, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.4608}\n",
      "边: 3 -> 5, 键: 0, 属性: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "边: 4 -> 13, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.1903}\n",
      "边: 4 -> 5, 键: 0, 属性: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "边: 5 -> 3, 键: 0, 属性: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "边: 5 -> 4, 键: 0, 属性: {'edge_type': 'pronoun_antecedent', 'weight': 1}\n",
      "边: 6 -> 14, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.6856}\n",
      "边: 6 -> 8, 键: 0, 属性: {'edge_type': 'similarity', 'weight': 0.4889921545982361}\n",
      "边: 6 -> 9, 键: 0, 属性: {'edge_type': 'similarity', 'weight': 0.3624955713748932}\n",
      "边: 8 -> 15, 键: 0, 属性: {'edge_type': 'word_sent', 'weight': 0.284}\n",
      "边: 8 -> 6, 键: 0, 属性: {'edge_type': 'similarity', 'weight': 0.4889921545982361}\n",
      "边: 9 -> 6, 键: 0, 属性: {'edge_type': 'similarity', 'weight': 0.3624955713748932}\n"
     ]
    }
   ],
   "source": [
    "for u, v, k, attr in graph_emb_list[0].edges(keys=True, data=True):\n",
    "     print(f\"边: {u} -> {v}, 键: {k}, 属性: {attr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.graph_utils import convert_graph_from_nx_to_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gr = convert_graph_from_nx_to_pyg(graph_emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HeteroData(\n",
       "   word={ x=[6, 768] },\n",
       "   sentence={ x=[10, 768] },\n",
       "   (sentence, similarity, sentence)={\n",
       "     edge_index=[2, 8],\n",
       "     edge_attr=[8, 1],\n",
       "   },\n",
       "   (sentence, pro_ant, sentence)={\n",
       "     edge_index=[2, 8],\n",
       "     edge_attr=[8, 1],\n",
       "   },\n",
       "   (sentence, has, word)={\n",
       "     edge_index=[2, 6],\n",
       "     edge_attr=[6, 1],\n",
       "   },\n",
       "   (word, in, sentence)={\n",
       "     edge_index=[2, 6],\n",
       "     edge_attr=[6, 1],\n",
       "   }\n",
       " )]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0): 0,\n",
       " (0, 0, 1): 1,\n",
       " (0, 0, 2): 2,\n",
       " (0, 1, 0): 3,\n",
       " (0, 1, 1): 4,\n",
       " (0, 1, 2): 5,\n",
       " (0, 2, 0): 6,\n",
       " (0, 2, 1): 7,\n",
       " (0, 2, 2): 8,\n",
       " (0, 2, 3): 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentid_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New emb. node  9 update with doc 2, sent 3\n",
      "  update. with embedding doc: 2, sent : 3\n",
      "  update. with embedding doc: 2, sent : 2\n",
      "  update. with embedding doc: 2, sent : 1\n",
      "  update. with embedding doc: 2, sent : 0\n",
      "New emb. node  5 update with doc 1, sent 2\n",
      "  update. with embedding doc: 1, sent : 2\n",
      "  update. with embedding doc: 1, sent : 1\n",
      "  update. with embedding doc: 1, sent : 0\n",
      "New emb. node  2 update with doc 0, sent 2\n",
      "  update. with embedding doc: 0, sent : 2\n",
      "  update. with embedding doc: 0, sent : 1\n",
      "  update. with embedding doc: 0, sent : 0\n"
     ]
    }
   ],
   "source": [
    "for sm in sentid_map:\n",
    "     pre_doc = -1\n",
    "     docs = [i for i in range(3)]\n",
    "     for (training_id, doc_id, sent_id), node_id in reversed(sm.items()):\n",
    "          if(doc_id == pre_doc):\n",
    "               print(f\"  update. with embedding doc: {docs[doc_id]}, sent : {sents[sent_id]}\")\n",
    "               continue\n",
    "          \n",
    "          sents = [i for i in range(sent_id + 1)]\n",
    "          pre_doc = doc_id\n",
    "          print(f\"New emb. node  {node_id} update with doc {doc_id}, sent {sent_id}\")\n",
    "          print(f\"  update. with embedding doc: {docs[doc_id]}, sent : {sents[sent_id]}\")\n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## position emdedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.graph_utils import get_sent_positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig,BertModel, BertTokenizer\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pos_emb_list, dos_list, sent_list = get_sent_positional_encoding(sentid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_pos_emb_list[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Absolute Embeddings Shape: torch.Size([7, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载 BERT 模型和分词器\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 获取 BERT 的绝对位置嵌入层\n",
    "position_embeddings = bert_model.embeddings.position_embeddings\n",
    "\n",
    "# 文档 ID（假设有 3 个文档）\n",
    "doc_ids = torch.tensor([0, 1, 2,3, 4,5,6])  # 文档 ID\n",
    "\n",
    "# 获取文档的绝对位置嵌入\n",
    "doc_absolute_embeddings = position_embeddings(doc_ids)  # (num_docs, hidden_size)\n",
    "print(\"Document Absolute Embeddings Shape:\", doc_absolute_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bert 相对位置\n",
    "bert_realtive_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "bert_realtive_config.position_embedding_type = \"relative_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_model = BertModel(bert_realtive_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Relative Embeddings Shape: torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "doc_rel_embeddings = relative_model.embeddings.position_embeddings(doc_ids)  # (num_docs, hidden_size)\n",
    "print(\"Document Relative Embeddings Shape:\", doc_rel_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare embedding: \n",
      " absolute: tensor([ 0.0175, -0.0256, -0.0366, -0.0253,  0.0080], grad_fn=<SliceBackward0>) \n",
      " relative: tensor([ 0.0202,  0.0040,  0.0096,  0.0082, -0.0004], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"compare embedding: \\n absolute: {doc_absolute_embeddings[0][:5]} \\n relative: {doc_rel_embeddings[0][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addition: tensor([ 0.0377, -0.0216, -0.0270, -0.0171,  0.0076], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = doc_absolute_embeddings[0] + doc_rel_embeddings[0]\n",
    "print(f\"addition: {a[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_embeddings = bert_model.embeddings.word_embeddings\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "word = \"hello\"\n",
    "inputs = tokenizer(word, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: {'input_ids': tensor([[ 101, 7592,  102]]), 'token_type_ids': tensor([[0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1]])}, \n",
      " size: torch.Size([3, 768]) \n",
      " embedding size: torch.Size([768]) \n",
      " embedding: tensor([-1.7358e-03, -2.3166e-02, -1.3069e-02, -9.3574e-03,  4.1518e-03,\n",
      "        -2.5549e-02, -4.2431e-02,  1.2142e-03, -2.0260e-02, -2.6077e-02,\n",
      "        -4.0625e-03, -3.3096e-02, -2.3811e-02,  3.2317e-02, -3.3522e-03,\n",
      "        -1.3013e-02, -3.6580e-02, -4.3474e-03,  1.8316e-02,  1.7741e-02,\n",
      "        -3.6144e-02, -2.3607e-02,  9.0560e-03, -6.0523e-03, -3.8177e-02,\n",
      "        -2.9239e-02,  8.6842e-03, -2.0197e-02,  1.6508e-02, -2.2251e-03,\n",
      "         4.0609e-03, -1.5051e-02, -2.1478e-02, -1.2696e-02, -5.7307e-03,\n",
      "        -1.8420e-02, -1.0483e-02, -2.1660e-02, -1.7329e-02,  3.5137e-02,\n",
      "        -8.4582e-03,  7.8621e-03, -3.4340e-02, -1.1105e-02, -1.1219e-03,\n",
      "         2.2187e-03, -9.5561e-02,  1.0324e-02,  1.2803e-04, -2.7626e-02,\n",
      "         3.0995e-02,  2.6175e-02, -4.3737e-02,  8.2593e-02,  6.6347e-03,\n",
      "        -5.5584e-03, -1.6278e-02,  2.7630e-03,  1.4116e-02, -1.3938e-02,\n",
      "        -6.4602e-03, -1.6330e-02, -1.4001e-02, -3.3631e-02, -2.6457e-02,\n",
      "         7.9601e-03,  1.9492e-02, -1.7429e-02,  2.8363e-03, -1.4404e-02,\n",
      "        -1.0051e-02, -1.5173e-03, -3.2671e-03, -5.6221e-04, -2.0207e-02,\n",
      "        -2.1304e-02, -1.3048e-02,  2.1949e-02, -2.1410e-02, -2.8614e-02,\n",
      "        -2.1300e-02,  2.1395e-03,  2.4366e-02, -3.1641e-03, -2.7069e-03,\n",
      "         1.3290e-02,  1.1198e-02,  6.0546e-03, -1.8785e-02, -6.3759e-03,\n",
      "        -2.3198e-02,  8.5076e-04, -5.3591e-03,  2.9536e-03, -1.8655e-02,\n",
      "        -7.6341e-03,  3.0326e-02,  4.9507e-03, -4.9681e-02,  6.3514e-03,\n",
      "         2.4023e-02,  4.6214e-03, -7.3984e-03, -2.9638e-03, -7.2725e-03,\n",
      "         4.7090e-02, -2.7003e-02,  3.3250e-03, -1.5045e-02, -1.7370e-02,\n",
      "         2.3286e-02,  6.5114e-03, -2.1307e-02, -7.6610e-03, -4.5322e-03,\n",
      "         2.6347e-02, -9.7358e-03,  7.1558e-03, -8.6445e-03, -1.5087e-02,\n",
      "         1.8610e-04,  2.4243e-01, -3.2586e-02, -1.3316e-02, -1.8092e-02,\n",
      "        -3.5120e-02, -1.7307e-02, -2.9258e-02, -4.6401e-03,  9.3698e-04,\n",
      "         2.3716e-02, -1.9249e-02,  1.9335e-02,  2.1590e-02, -2.1742e-02,\n",
      "         4.5261e-03,  1.6062e-03,  1.0872e-02, -1.8671e-02,  2.6075e-01,\n",
      "         7.1831e-03, -8.0252e-03,  1.7431e-02,  1.5701e-02, -2.3317e-02,\n",
      "        -3.5901e-01,  2.1074e-02, -1.8400e-02, -2.1125e-02, -3.2464e-02,\n",
      "         1.0263e-02, -9.9098e-03, -5.2872e-02, -7.4522e-03, -9.5826e-03,\n",
      "        -2.4865e-02, -5.4704e-03, -1.6079e-02, -2.7348e-02, -1.2879e-01,\n",
      "        -2.5228e-03, -4.0544e-04, -2.1771e-02, -2.0489e-02,  4.1792e-03,\n",
      "         3.4863e-03,  4.7779e-03, -2.3330e-02,  1.2980e-01, -1.0573e-02,\n",
      "        -6.0423e-04,  8.2528e-03, -2.3029e-02, -2.6911e-02,  1.6760e-02,\n",
      "         1.7802e-01,  1.5836e-02, -9.2394e-03, -3.1283e-02, -8.7646e-03,\n",
      "         8.3150e-03, -1.1992e-02, -1.6058e-02, -1.7446e-02,  1.4764e-02,\n",
      "        -1.7323e-03, -2.1639e-02, -2.3252e-02, -1.4689e-02,  2.4058e-02,\n",
      "        -9.8664e-03,  1.6605e-02, -2.7077e-02, -1.8061e-02, -8.4598e-03,\n",
      "        -2.0852e-03, -3.0874e-02, -1.5645e-02, -2.2022e-02, -3.6538e-02,\n",
      "        -3.0435e-03,  2.3975e-02,  2.5483e-02, -2.7389e-02, -9.0837e-03,\n",
      "         1.2114e-02, -2.2917e-02, -9.0293e-03, -8.1686e-03, -1.2370e-02,\n",
      "         1.2301e-02, -7.0156e-03, -5.3365e-03, -4.9689e-03, -4.5113e-03,\n",
      "        -8.1879e-02,  3.9295e-02, -3.4677e-03,  3.1139e-02,  2.1681e-02,\n",
      "         5.0266e-03,  6.7703e-03,  1.3449e-02, -5.7628e-03,  8.1726e-03,\n",
      "         7.1820e-02,  2.2831e-02, -1.7285e-03,  1.4445e-02, -9.4734e-03,\n",
      "         1.1277e-03, -1.0688e-03, -4.0152e-02, -1.5744e-02, -6.1262e-03,\n",
      "         8.1809e-03,  1.4575e-02, -2.4198e-02, -7.3214e-03, -6.0806e-03,\n",
      "        -2.1932e-02, -2.4394e-02, -3.2445e-02, -1.0972e-02, -2.4887e-02,\n",
      "         2.6437e-02,  2.8396e-02, -2.5322e-02,  2.3655e-03, -3.1477e-02,\n",
      "        -4.4005e-02, -4.9371e-02,  3.4624e-03,  1.6528e-02,  2.9599e-02,\n",
      "         1.2908e-02,  8.6706e-03, -3.5103e-02, -2.8443e-03,  6.9634e-03,\n",
      "        -3.1067e-02, -5.1027e-02, -1.0373e-02,  2.3182e-02, -2.2134e-02,\n",
      "        -1.6709e-03, -4.6561e-03, -1.7425e-02, -8.4447e-03, -1.7160e-02,\n",
      "        -1.4423e-02,  1.2851e-02, -2.7923e-03,  3.9091e-03,  4.8969e-03,\n",
      "        -3.0823e-02, -2.3094e-02,  3.9338e-03,  4.6812e-03, -1.5646e-02,\n",
      "        -6.4299e-03,  6.5617e-03, -3.5819e-02,  1.4061e-02,  5.4201e-03,\n",
      "        -1.1129e-02, -8.1433e-03, -3.8295e-02, -1.1807e-02,  1.0909e-02,\n",
      "        -1.7354e-02,  1.1144e-03,  2.5944e-02, -2.3292e-02, -4.0253e-02,\n",
      "         7.8512e-03,  3.0259e-02, -9.8325e-03, -1.3974e-02, -1.3638e-02,\n",
      "        -8.1133e-03, -2.8126e-02, -6.2622e-03, -2.0735e-02, -6.7174e-02,\n",
      "        -5.3152e-03, -7.2768e-03, -1.6172e-02, -3.9486e-01, -1.7087e-02,\n",
      "         2.9243e-03,  3.0560e-02,  3.7845e-03, -3.1331e-02,  5.2005e-03,\n",
      "        -1.2928e-03,  2.4303e-03, -2.3301e-03, -3.4332e-04,  7.8255e-02,\n",
      "         9.2426e-03,  3.2408e-03, -3.6587e-02, -4.8514e-03, -1.6185e-02,\n",
      "         1.5615e-02, -1.5118e-02,  3.0938e-03, -5.5121e-03,  1.1980e-02,\n",
      "        -2.8721e-02, -6.8437e-03,  5.2552e-03, -1.6268e-02,  1.2299e-02,\n",
      "        -2.0882e-03,  3.6163e-02,  8.2276e-03, -2.0305e-02,  9.6350e-03,\n",
      "        -2.2444e-02, -2.9378e-02, -7.0414e-04,  1.4478e-02, -2.3232e-03,\n",
      "         1.0848e-02, -2.4457e-02, -7.8106e-03, -1.6906e-02, -3.2570e-03,\n",
      "        -3.3953e-02, -1.5618e-02, -5.2256e-03,  3.7344e-03,  4.4006e-04,\n",
      "        -1.9596e-02, -2.2056e-02, -7.6858e-04, -1.4726e-02,  2.0528e-02,\n",
      "         1.6946e-02, -2.0331e-02,  4.4455e-03, -2.3433e-02,  3.3435e-02,\n",
      "         1.4453e-03,  5.3365e-04, -2.7627e-02, -7.7802e-03, -2.9266e-02,\n",
      "        -3.3526e-02, -4.9708e-02, -5.6849e-03, -2.3192e-02, -3.2910e-02,\n",
      "        -3.0071e-02, -2.6436e-02, -1.1077e-02, -2.6462e-02, -5.6167e-03,\n",
      "         1.5333e-03, -2.7279e-01, -2.3874e-02, -2.5613e-02, -2.5364e-03,\n",
      "        -2.0681e-02,  1.7340e-02,  5.1562e-03, -2.1262e-02,  4.3729e-03,\n",
      "        -1.3570e-02, -2.8668e-02,  1.6541e-03, -3.1750e-02, -3.2015e-02,\n",
      "        -2.8366e-02,  3.6004e-03,  5.1748e-03, -3.7864e-02, -6.1798e-03,\n",
      "        -6.3287e-03, -1.9143e-02, -2.5098e-02, -3.0664e-02, -1.3941e-02,\n",
      "        -6.2105e-03, -2.0566e-03,  5.0565e-03,  9.5581e-03,  2.7047e-03,\n",
      "        -1.9883e-02, -1.5748e-02, -1.6443e-02, -1.1316e-02,  4.0365e-03,\n",
      "         1.1726e-02, -4.5646e-03, -2.5639e-02, -7.0981e-03,  3.4252e-02,\n",
      "        -1.8752e-02, -3.5890e-02, -2.1493e-02, -3.6568e-02, -3.8988e-03,\n",
      "        -3.6642e-02,  1.3420e-02, -2.4595e-02,  2.8501e-02, -2.7706e-02,\n",
      "        -2.0577e-02, -1.1390e-03,  3.3286e-03,  1.7531e-02, -1.5391e-02,\n",
      "         8.0903e-03,  3.1978e-03,  1.2510e-03,  7.7622e-03,  9.1389e-03,\n",
      "        -2.7370e-02, -1.0823e-02, -2.3628e-02,  1.0598e-01,  3.2543e-03,\n",
      "        -1.6380e-03, -9.3063e-03, -2.5459e-03,  4.7907e-03, -3.5416e-02,\n",
      "        -8.9940e-04, -1.7011e-02, -2.7001e-02,  3.0898e-03, -1.4529e-02,\n",
      "        -9.5096e-03, -1.6706e-02, -1.2348e-02, -1.4616e-02,  7.8516e-03,\n",
      "        -6.2680e-03,  3.7409e-02, -5.7728e-03, -4.4295e-03,  1.4831e-02,\n",
      "         2.2662e-02, -2.2636e-02, -3.5504e-02,  2.2122e-02, -1.4760e-02,\n",
      "        -5.8518e-02, -3.3561e-03,  4.1044e-03,  1.2103e-02, -3.0969e-03,\n",
      "        -7.5363e-03, -1.4698e-02, -4.8795e-03,  2.5867e-02,  3.4629e-02,\n",
      "        -7.7050e-03, -2.1577e-02, -1.5535e-02,  1.4731e-02,  1.8304e-02,\n",
      "        -3.1342e-03, -9.9087e-03,  4.8555e-03, -6.8608e-03,  1.5600e-02,\n",
      "         1.4116e-02,  2.0200e-03, -3.5152e-03, -2.8746e-02,  1.6175e-02,\n",
      "         2.4819e-03,  1.4098e-02, -2.2291e-02, -2.5520e-02, -2.5537e-02,\n",
      "         8.0375e-03, -1.2813e-03, -4.6129e-03, -5.3054e-02, -1.6464e-02,\n",
      "        -1.9982e-02, -2.1858e-02, -9.5877e-03, -3.7020e-03, -1.7625e-02,\n",
      "        -2.1874e-02, -1.6902e-02,  2.2182e-03, -1.7348e-02, -6.7836e-03,\n",
      "        -1.2638e-02,  2.4415e-03,  7.7583e-02,  7.7404e-03, -2.5679e-03,\n",
      "        -9.7557e-03, -3.1591e-03,  1.3182e-02,  5.0115e-03,  1.6427e-02,\n",
      "        -1.4060e-02, -2.0809e-02,  5.2214e-03,  3.8631e-03,  5.3292e-02,\n",
      "         9.8905e-03, -5.2437e-02, -6.5160e-03, -1.5556e-03, -3.0105e-02,\n",
      "         3.9256e-03, -1.5503e-02,  2.3169e-03, -2.6431e-02, -9.2944e-03,\n",
      "        -1.4950e-02,  1.2404e-01,  3.4933e-03, -4.6107e-03,  5.1243e-03,\n",
      "         1.2066e-01,  2.3006e-02, -6.8218e-03, -3.5399e-02, -1.1461e-02,\n",
      "         1.1129e-02, -3.0806e-02, -1.3533e-03,  1.2217e-02,  4.8399e-03,\n",
      "        -2.6695e-02,  9.6176e-03, -1.8811e-03, -1.2646e-02,  2.9076e-02,\n",
      "        -9.9841e-03, -7.8361e-03, -1.3432e-02, -3.9595e-02, -1.4921e-02,\n",
      "         1.4814e-02,  2.1313e-03, -1.5138e-02,  1.0509e-02, -6.3509e-03,\n",
      "        -3.6941e-02, -2.2625e-02,  3.1659e-02, -9.3043e-03,  1.5527e-02,\n",
      "        -4.6052e-03, -5.7361e-03,  1.3739e-02, -1.6955e-02, -1.3516e-02,\n",
      "        -3.0557e-02, -1.7881e-03, -2.7524e-02, -1.5104e-02,  2.1082e-02,\n",
      "        -6.1162e-03, -5.1530e-04,  6.7046e-03, -5.4662e-02, -6.5256e-03,\n",
      "         7.5323e-03, -3.2174e-02, -3.0057e-02, -6.0562e-03,  1.3010e-02,\n",
      "         1.1240e-03, -1.7210e-02,  2.9123e-02, -9.5524e-03,  1.3056e-02,\n",
      "        -1.1706e-02,  2.2561e-02, -1.1081e-03, -4.7589e-03,  1.0941e-02,\n",
      "        -1.4096e-02, -1.0737e-02, -7.3204e-03, -3.1151e-02,  8.2211e-03,\n",
      "        -8.1494e-03, -3.1798e-02,  1.1633e-02, -1.8629e-02, -1.8039e-02,\n",
      "        -2.9404e-02,  1.6097e-03, -1.8887e-02, -2.3108e-02,  2.3055e-02,\n",
      "        -1.9827e-02,  3.8473e-03, -7.3112e-03,  1.9578e-03, -6.9686e-03,\n",
      "        -2.3950e-03,  2.6005e-02, -3.0258e-03,  9.9153e-03,  1.1708e-02,\n",
      "        -3.3441e-02,  2.4346e-03,  1.0963e-02, -1.6017e-02, -8.6628e-03,\n",
      "        -1.7354e-02,  2.0477e-02,  8.6791e-03, -1.5186e-02, -2.4023e-02,\n",
      "        -6.8067e-03, -1.5395e-02, -3.3710e-02, -8.3805e-03,  5.3821e-03,\n",
      "        -1.6152e-02, -2.8267e-03,  5.6079e-04, -1.0143e-02, -1.6109e-02,\n",
      "        -7.7184e-03, -2.7426e-02, -9.8475e-03, -4.6382e-02, -2.8226e-02,\n",
      "        -5.1360e-03, -9.9593e-04,  4.2456e-03, -3.9082e-03, -2.3596e-02,\n",
      "        -6.4674e-03, -1.1135e-02, -2.1788e-02, -1.5457e-02,  2.0707e-02,\n",
      "        -8.3904e-03,  8.2368e-03, -2.6734e-02, -1.2427e-02,  4.1301e-03,\n",
      "         3.3065e-02,  3.1714e-03, -9.5532e-03, -1.7193e-03,  5.9247e-03,\n",
      "         1.1461e-03, -1.1274e-02, -1.9366e-02, -2.6680e-02,  1.2288e-02,\n",
      "        -7.5536e-03, -1.1249e-02, -2.3647e-02,  1.6978e-02, -1.6534e-02,\n",
      "        -1.4827e-02,  6.3395e-03, -3.7339e-02, -4.3956e-03, -2.5280e-02,\n",
      "        -1.7497e-02, -9.6776e-03, -9.1594e-03,  1.1261e-02, -3.2790e-02,\n",
      "        -6.8797e-03, -1.6201e-02, -8.8068e-03,  2.7601e-04, -8.7726e-02,\n",
      "         7.5301e-03,  1.1987e-02,  5.7527e-04,  2.4660e-03, -1.7768e-02,\n",
      "        -3.2147e-02,  2.1714e-02,  1.2135e-02,  1.2414e-02, -2.4989e-02,\n",
      "         2.0696e-02, -1.2062e-02,  4.4038e-03, -3.1476e-02,  5.0566e-03,\n",
      "         1.4565e-02, -1.8235e-02, -3.1435e-03,  2.8273e-03, -4.4024e-04,\n",
      "        -1.2264e-03,  1.7721e-03,  3.8873e-03, -2.3843e-02, -1.3759e-02,\n",
      "        -2.7950e-02, -3.0948e-02, -1.0461e-02,  5.2236e-03, -6.5106e-03,\n",
      "         5.8557e-03, -4.6708e-03,  1.7903e-02, -3.9362e-02, -3.3031e-02,\n",
      "        -1.7815e-02,  1.8222e-02, -1.1958e-02, -1.5978e-03,  1.1494e-02,\n",
      "        -8.5796e-03, -1.0361e-02,  9.0367e-03, -4.2112e-02,  1.8237e-04,\n",
      "         2.8958e-03,  6.5784e-03,  1.1320e-02,  2.1157e-02,  8.2902e-03,\n",
      "        -3.4583e-02,  3.1578e-03, -8.0164e-03, -1.0228e-02,  1.3442e-03,\n",
      "         3.5639e-03, -1.3009e-02,  1.5720e-02, -2.4315e-02,  5.7832e-04,\n",
      "         1.3061e-02, -1.0766e-02, -3.7497e-04,  8.7986e-04,  1.2603e-02,\n",
      "        -1.9607e-02, -3.0227e-04, -8.4212e-03], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "token = txt_embeddings(inputs['input_ids'][0])\n",
    "avg = torch.mean(token, dim=0)\n",
    "print(f\"ids: {inputs}, \\n size: {token.shape} \\n embedding size: {avg.shape} \\n embedding: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([3, 5])\n",
      "tensor([[-1.2431, -0.5892, -0.9663, -0.8608, -1.4063],\n",
      "        [ 0.0142, -1.5973,  0.1458, -0.2300, -0.3988],\n",
      "        [ 1.3363,  0.9640,  1.6577,  0.1071, -1.1673]])\n",
      "Mean tensor shape: torch.Size([5])\n",
      "tensor([ 0.0358, -0.4075,  0.2791, -0.3279, -0.9908])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建一个形状为 [3, 5] 的张量\n",
    "tensor = torch.randn(3, 5)  # 3 个 768 维的向量\n",
    "print(\"Original tensor shape:\", tensor.shape)  # 输出: torch.Size([3, 768])\n",
    "print(tensor)\n",
    "# 对第一个维度取平均\n",
    "mean_tensor = torch.mean(tensor, dim=0)  # dim=0 表示对第一个维度取平均\n",
    "print(\"Mean tensor shape:\", mean_tensor.shape)  # 输出: torch.Size([1, 768])\n",
    "print(mean_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 19:51:26,426 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu - SentenceTransformer.py:210\n",
      "2025-01-23 19:51:26,426 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2 - SentenceTransformer.py:218\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 384)\n",
      "tensor([[1.0000, 0.6660, 0.1046, 0.1400, 0.0599],\n",
      "        [0.6660, 1.0000, 0.1411, 0.1332, 0.1152],\n",
      "        [0.1046, 0.1411, 1.0000, 0.1124, 0.1256],\n",
      "        [0.1400, 0.1332, 0.1124, 1.0000, 0.8318],\n",
      "        [0.0599, 0.1152, 0.1256, 0.8318, 1.0000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# The sentences to encode\n",
    "sentences = [\n",
    "     \"The weather is lovely today.\",\n",
    "     \"It's so sunny outside!\",\n",
    "     \"He drove to the stadium.\",\n",
    "     \"Mary likes bike.\",\n",
    "     \"Mary hates bike.\"\n",
    "]\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 and 0 connect, similarity = 0.6659553050994873\n",
      "2 and 1 connect, similarity = 0.14114472270011902\n",
      "3 and 0 connect, similarity = 0.14001354575157166\n"
     ]
    }
   ],
   "source": [
    "n = len(embeddings)\n",
    "for i in range(n):\n",
    "     for j in range(n):\n",
    "          if j < i and similarities[i][j] >= 0.14:\n",
    "               print(f\"{i} and {j} connect, similarity = {similarities[i][j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# 加载 BERT tokenizer 和模型\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入单词\n",
    "word = \"hello\"\n",
    "\n",
    "# 将单词转换为 token ID\n",
    "inputs = bert_tokenizer(word, return_tensors=\"pt\")  # 返回 PyTorch 张量\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# 打印 token ID\n",
    "print(\"Input IDs:\", input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 BERT 的 embedding 层\n",
    "embedding_layer = bert_model.embeddings.word_embeddings\n",
    "\n",
    "# 将 token ID 转换为 word embedding\n",
    "with torch.no_grad():\n",
    "     word_embedding = embedding_layer(input_ids)\n",
    "     \n",
    "# 如果单词被拆分为多个 subword tokens，取平均\n",
    "if word_embedding.shape[1] > 1:\n",
    "     word_embedding = word_embedding.mean(dim=1)  # 沿 sequence_length 维度取平均\n",
    "\n",
    "\n",
    "# 打印 word embedding 的形状\n",
    "print(\"Word Embedding Shape:\", word_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main process test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 26.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.graph_utils import create_graph, embed_nodes\n",
    "from utils.data_preprocess_utils import define_node_edge\n",
    "\n",
    "word_map, sent_map, edges, sentid_map = define_node_edge(test_docs_list, edge_similarity_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list = create_graph(word_map, sent_map, edges)\n",
    "graph_with_emb = embed_nodes(graph_list, sentid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph embedding combine test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# 假设 GNN 模型已经定义并生成 embedding\n",
    "class GNNModel(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size):\n",
    "          super().__init__()\n",
    "          self.fc = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "     def forward(self, graph_input):\n",
    "          # 这里假设 graph_input 是图的表示，例如节点特征\n",
    "          # 返回 GNN 生成的 embedding\n",
    "          return self.fc(graph_input)\n",
    "\n",
    "# 初始化 GNN 模型\n",
    "gnn_model = GNNModel(input_size=128, hidden_size=256)  # 假设 GNN 的 hidden size 是 256\n",
    "\n",
    "# 初始化 T5 模型和 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# 假设输入文本和图的表示\n",
    "input_text = \"This is an example sentence.\"\n",
    "graph_input = torch.randn(1, 10, 128)  # [batch_size, seq_len, gnn_input_size]\n",
    "\n",
    "# 1. 使用 GNN 生成 embedding\n",
    "gnn_embeddings = gnn_model(graph_input)  # [batch_size, seq_len, gnn_hidden_size]\n",
    "\n",
    "# 2. 使用 T5 tokenizer 对输入文本进行编码\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids  # [batch_size, seq_len]\n",
    "\n",
    "# 3. 获取 T5 的 token embedding\n",
    "token_embeddings = t5_model.get_input_embeddings()(input_ids)  # [batch_size, seq_len, t5_hidden_size]\n",
    "\n",
    "# 4. 将 GNN embedding 和 T5 token embedding 拼接\n",
    "# 首先需要将 GNN embedding 的序列长度与 T5 token embedding 对齐\n",
    "# 这里假设 GNN embedding 的序列长度与 T5 token embedding 相同\n",
    "# 如果不同，可以通过插值或截断对齐\n",
    "combined_embeddings = torch.cat([token_embeddings, gnn_embeddings], dim=-1)  # [batch_size, seq_len, t5_hidden_size + gnn_hidden_size]\n",
    "\n",
    "# 5. 通过线性变换将拼接后的 embedding 映射到 T5 的 hidden size\n",
    "linear_layer = nn.Linear(t5_model.config.hidden_size + gnn_embeddings.size(-1), t5_model.config.hidden_size)\n",
    "mapped_embeddings = linear_layer(combined_embeddings)  # [batch_size, seq_len, t5_hidden_size]\n",
    "\n",
    "# 6. 使用 inputs_embeds 参数传入自定义 embedding\n",
    "outputs = t5_model(inputs_embeds=mapped_embeddings)\n",
    "\n",
    "# 7. 获取生成的输出\n",
    "generated_ids = t5_model.generate(inputs_embeds=mapped_embeddings)\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Summary:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get embedding\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# 加载 T5 tokenizer 和模型\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# 输入文本\n",
    "text = \"Translate English to French: The house is wonderful.\"\n",
    "\n",
    "# 将文本转换为 token ID 序列\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# 使用 embedding 层生成词向量\n",
    "with torch.no_grad():\n",
    "     inputs_embeds = model.get_input_embeddings()(input_ids) ##  inputs_embeds = model.encoder.embed_tokens(input_ids)\n",
    "\n",
    "# 打印词向量的形状\n",
    "print(\"Inputs Embeds Shape:\", inputs_embeds.shape)\n",
    "\n",
    "# 打印词向量\n",
    "print(\"Inputs Embeds:\", inputs_embeds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coreferee_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
